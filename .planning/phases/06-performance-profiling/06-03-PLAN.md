---
phase: 06-performance-profiling
plan: 03
type: execute
---

<objective>
Profile WebSocket server performance and identify scaling limits with concurrent connections and message broadcasting.

Purpose: Understand WebSocket performance characteristics, memory usage patterns, and connection lifecycle efficiency before optimization work.
Output: WebSocket profiling report with connection limits, broadcast performance, and memory leak detection.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-performance-profiling/06-RESEARCH.md
@server/src/ws/server.ts
@server/src/ws/types.ts
@server/src/index.ts
@server/load-tests/websocket-load.js
@server/profiling/BASELINE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Profile WebSocket server under concurrent connection load</name>
  <files>server/profiling/06-03-websocket-profile.md, server/profiling/websocket-concurrent-test.js</files>
  <action>
    Profile WebSocket server performance with increasing concurrent connections:

    1. Create WebSocket concurrency test script server/profiling/websocket-concurrent-test.js:
       ```javascript
       import WebSocket from 'ws';
       const concurrentLevels = [10, 50, 100, 500, 1000];

       for (const concurrent of concurrentLevels) {
         console.log(`\nTesting ${concurrent} concurrent connections...`);
         const connected = new Set();
         let messagesReceived = 0;
         const startTime = Date.now();

         // Create connections
         for (let i = 0; i < concurrent; i++) {
           const ws = new WebSocket('ws://localhost:8000/ws');
           ws.on('open', () => {
             connected.add(ws);
             ws.send(JSON.stringify({ type: 'subscribe', matchId: 1 }));
           });
           ws.on('message', (data) => {
             messagesReceived++;
           });
           ws.on('error', (err) => {
             console.error(`Connection ${i} error:`, err.message);
           });
         }

         // Wait for connections to establish
         await new Promise(resolve => setTimeout(resolve, 5000));

         const connectionTime = Date.now() - startTime;
         console.log(`Connected: ${connected.size}/${concurrent}`);
         console.log(`Connection time: ${connectionTime}ms`);

         // Monitor for 30 seconds
         const startMessages = messagesReceived;
         await new Promise(resolve => setTimeout(resolve, 30000));
         const messagesPerSec = (messagesReceived - startMessages) / 30;

         console.log(`Messages/sec: ${messagesPerSec.toFixed(2)}`);

         // Cleanup
         connected.forEach(ws => ws.close());
         await new Promise(resolve => setTimeout(resolve, 2000));
       }
       ```

    2. Start server: cd server && npm start

    3. In another terminal, run the test:
       node server/profiling/websocket-concurrent-test.js

    4. Capture all output to server/profiling/06-03-websocket-profile.md

    5. Document metrics for each concurrency level:
       - Time to establish all connections
       - Successfully connected vs. attempted
       - Message throughput (messages/sec)
       - Any errors or connection failures
       - Server memory usage (add memory logging if needed)

    This identifies the server's concurrent connection limit.
  </action>
  <verify>File 06-03-websocket-profile.md exists with connection metrics for multiple concurrency levels (10 through 1000+)</verify>
  <done>WebSocket concurrent connection performance documented across multiple load levels</done>
</task>

<task type="auto">
  <name>Task 2: Profile broadcast performance and message throughput</name>
  <files>server/profiling/06-03-broadcast-profile.md, server/profiling/broadcast-test.js</files>
  <action>
    Profile message broadcast performance at scale:

    1. Create broadcast test script server/profiling/broadcast-test.js:
       ```javascript
       import WebSocket from 'ws';

       const CONNECTIONS = 100;
       const MATCH_ID = 1;
       const clients = [];

       // Connect all clients to same match
       for (let i = 0; i < CONNECTIONS; i++) {
         const ws = new WebSocket('ws://localhost:8000/ws');
         ws.on('open', () => {
           ws.send(JSON.stringify({ type: 'subscribe', matchId: MATCH_ID }));
           clients.push(ws);
         });
       }

       await new Promise(resolve => setTimeout(resolve, 5000));
       console.log(`Connected ${clients.length} clients to match ${MATCH_ID}`);

       // Simulate commentary broadcasts from server
       // (This requires triggering commentary creation via HTTP API)
       // Use autocannon to POST commentary while monitoring WebSocket clients

       const WebSocket = require('ws');
       const testMessages = 100;
       let messagesReceived = 0;

       clients.forEach(ws => {
         ws.on('message', () => {
           messagesReceived++;
         });
       });

       // Trigger commentary creation via HTTP
       const autocannon = require('autocannon');
       await autocannon({
         url: 'http://localhost:8000',
         connections: 10,
         duration: 30,
         requests: [{
           method: 'POST',
           path: `/matches/${MATCH_ID}/commentary`,
           headers: { 'content-type': 'application/json' },
           body: JSON.stringify({ minute: 1, text: 'Test commentary' })
         }]
       });

       console.log(`Total messages received: ${messagesReceived}`);
       console.log(`Per client: ${(messagesReceived / CONNECTIONS).toFixed(2)}`);
       ```

    2. Run with server started and capture results to server/profiling/06-03-broadcast-profile.md

    3. Document:
       - Broadcast latency per message
       - Message delivery success rate
       - Server CPU usage during broadcasts
       - Any message loss or delivery failures

    This identifies broadcast performance limits.
  </action>
  <verify>File 06-03-broadcast-profile.md exists with broadcast performance metrics including latency, success rate, and CPU usage</verify>
  <done>Message broadcast performance profiled under load</done>
</task>

<task type="auto">
  <name>Task 3: Detect memory leaks and connection lifecycle issues</name>
  <files>server/profiling/06-03-memory-analysis.md, server/src/ws/server.ts</files>
  <action>
    Analyze WebSocket server for memory leaks and connection lifecycle issues:

    1. Review server/src/ws/server.ts for lifecycle management:
       - Check for proper close event handlers
       - Verify connections are removed from tracking structures on close
       - Look for event listeners that aren't cleaned up
       - Check for subscription cleanup on unsubscribe

    2. Create memory monitoring script server/profiling/memory-test.js:
       ```javascript
       import WebSocket from 'ws';

       function getMemoryUsage() {
         const used = process.memoryUsage();
         return {
           rss: Math.round(used.rss / 1024 / 1024) + 'MB',
           heapTotal: Math.round(used.heapTotal / 1024 / 1024) + 'MB',
           heapUsed: Math.round(used.heapUsed / 1024 / 1024) + 'MB',
           external: Math.round(used.external / 1024 / 1024) + 'MB'
         };
       }

       console.log('Initial memory:', getMemoryUsage());

       // Create and close connections repeatedly
       for (let cycle = 0; cycle < 10; cycle++) {
         console.log(`\nCycle ${cycle + 1}:`);

         const connections = [];
         for (let i = 0; i < 100; i++) {
           const ws = new WebSocket('ws://localhost:8000/ws');
           connections.push(ws);
         }

         await new Promise(resolve => setTimeout(resolve, 2000));
         console.log('After 100 connections:', getMemoryUsage());

         connections.forEach(ws => ws.close());
         await new Promise(resolve => setTimeout(resolve, 2000));
         console.log('After closing all:', getMemoryUsage());

         // Force garbage collection if available
         if (global.gc) {
           global.gc();
           console.log('After GC:', getMemoryUsage());
         }
       }

       console.log('\nFinal memory:', getMemoryUsage());
       console.log('\nIf memory grows consistently across cycles, there is a leak.');
       ```

    3. Run with: node --expose-gc server/profiling/memory-test.js

    4. Create analysis report server/profiling/06-03-memory-analysis.md:
       - **Code Review Findings**: Lifecycle management issues found in server.ts
       - **Memory Test Results**: Memory usage across connection cycles
       - **Leak Detection**: Whether memory grows consistently (indicates leak)
       - **Recommendations for Phase 7**: Fixes needed (cleanup handlers, GC tuning)

    This identifies memory management issues before optimization.
  </action>
  <verify>File 06-03-memory-analysis.md exists with code review findings, memory test results, leak detection analysis, and Phase 7 recommendations</verify>
  <done>WebSocket memory and lifecycle analysis completed with optimization recommendations</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] WebSocket server profiled under concurrent connection load (multiple levels)
- [ ] Broadcast performance measured with message throughput
- [ ] Memory leak detection executed across multiple connection cycles
- [ ] Code review identified lifecycle management issues
- [ ] Comprehensive analysis report with Phase 7 recommendations created
</verification>

<success_criteria>
- WebSocket connection scaling limits identified
- Broadcast performance characteristics documented
- Memory leaks or lifecycle issues detected
- Optimization recommendations documented for Phase 7
- All profiling data consolidated into analysis report
</success_criteria>

<output>
After completion, create `.planning/phases/06-performance-profiling/06-03-SUMMARY.md`:

# Phase 6 Plan 3: WebSocket Profiling Summary

**Profiled WebSocket server performance and identified scaling limits, memory leaks, and optimization opportunities.**

## Accomplishments

- Tested WebSocket server with 10-1000+ concurrent connections
- Profiled message broadcast performance and throughput
- Detected memory leaks and connection lifecycle issues
- Created comprehensive WebSocket performance analysis

## Files Created/Modified

- `server/profiling/websocket-concurrent-test.js` - Connection load test
- `server/profiling/broadcast-test.js` - Broadcast performance test
- `server/profiling/memory-test.js` - Memory leak detection
- `server/profiling/06-03-websocket-profile.md` - Connection metrics
- `server/profiling/06-03-broadcast-profile.md` - Broadcast metrics
- `server/profiling/06-03-memory-analysis.md` - Memory and lifecycle analysis

## Key Findings

- [Maximum concurrent connections before degradation]
- [Broadcast throughput and latency characteristics]
- [Memory leaks or lifecycle issues detected]
- [Specific code locations requiring fixes]

## Next Step

Phase 6 complete, ready for Phase 7 (Performance Optimization)
</output>
